{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Лабораторная работа №2 по курсу \"Машинное обучение\"\n",
    "## Базаргармаев Н.Д. 401Б\n",
    "\n",
    "## Алгоритмы классификации"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Загружаем нужные модули"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score , recall_score , f1_score\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Считаем обработанный в лабороторной №1 датасет и показываем первые строки"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "dataset=read_csv('remastered_dataset.csv')\n",
    "dataset.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>target</th>\n",
       "      <th>PhD</th>\n",
       "      <th>bachelor</th>\n",
       "      <th>elementary education</th>\n",
       "      <th>master</th>\n",
       "      <th>other</th>\n",
       "      <th>school graduate</th>\n",
       "      <th>married</th>\n",
       "      <th>refuse to answer</th>\n",
       "      <th>single</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>280000</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50000</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50000</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LIMIT_BAL  SEX  AGE  target  PhD  bachelor  elementary education  master  \\\n",
       "0     280000    1   30       1    0         1                     0       0   \n",
       "1      50000    0   22       1    0         1                     0       0   \n",
       "2      50000    0   26       1    0         0                     0       1   \n",
       "3      20000    1   21       1    0         1                     0       0   \n",
       "4      20000    1   23       1    0         0                     0       0   \n",
       "\n",
       "   other  school graduate  married  refuse to answer  single  \n",
       "0      0                0        0                 0       1  \n",
       "1      0                0        0                 0       1  \n",
       "2      0                0        0                 0       1  \n",
       "3      0                0        0                 0       1  \n",
       "4      0                1        0                 0       1  "
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Делим выборку на трейн и тест в соотношении 30% для теста."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#разбиваю выборку на трейн и тест. Для теста выделяю 30% выборки.\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset.drop('target',axis=1), dataset['target'], test_size=0.3,shuffle=True,random_state=15)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Создаем функцию для подсчета метрик "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def metrics(pred, Y_test):\n",
    "    \n",
    "    \n",
    "    print(\"Accuracy: \", (pred==Y_test).mean())\n",
    "    print(\"Pprecision: \", precision_score(pred, Y_test, average='micro'))\n",
    "    print(\"Recall: \", recall_score(pred, Y_test, average='micro'))\n",
    "    print(\"F1: \", f1_score(pred, Y_test, average='micro'))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Логистическая регрессия"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#Я реализовал логистическую регрессию в виде класса с 2 публичными методами. fit - для обучения, predict - для предсказания\n",
    "class LogReg:\n",
    "    #задаем количество итераций при инициализации класса 100000\n",
    "    def __init__(self,num_iter = 100000):\n",
    "        self.num_iter=num_iter\n",
    "        self.beta=1\n",
    "        \n",
    "     #метод обучающий модель   \n",
    "    def fit(self,x,y):\n",
    "        #задаем матрицу весов в виде единичной матрицы \n",
    "        self.beta = np.ones(x.shape[1])\n",
    "        for i in range(self.num_iter):\n",
    "            h = self._sigmoid(x, self.beta)#считаем сигмойду\n",
    "            gradient = self._gradient_spusk(x, h, y)#спускаемся по градиенту\n",
    "            self.beta =self._weight_update(self.beta, 0.1, gradient)#обновляем веса\n",
    "    \n",
    "    #приватный метод, считающий сигмойду\n",
    "    def _sigmoid(self,X, weight):\n",
    "        z = np.dot(X, weight)\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    #приватная функция для градиентного шага\n",
    "    def _gradient_spusk(self,X, H, Y):\n",
    "        return np.dot(X.T, (H - Y)) / Y.shape[0]\n",
    "    \n",
    "    #приватная функция для обноления весов\n",
    "    def _weight_update(self,weight, learning_rate, gradient):\n",
    "        return weight - learning_rate * gradient\n",
    "    \n",
    "    \n",
    "    def predict(self,test):\n",
    "        final_result=[]\n",
    "        \n",
    "        #приминяем сигмойду к тестовым данным\n",
    "        result = self._sigmoid(test, self.beta)\n",
    "        \n",
    "        #выбираем  метки для теста \n",
    "        for i in result:\n",
    "            final_result.append(self._onepred(i))\n",
    "        \n",
    "        \n",
    "        return final_result\n",
    "        \n",
    "        \n",
    "        \n",
    "    #приватная функция для одного предсказания    \n",
    "    def _onepred(self,x):\n",
    "        if x < 0.5:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "#обучаю свою модель \n",
    "my_lg=LogReg()\n",
    "my_lg.fit(X_train,y_train)\n",
    "#делаем предсказания на трейне и на тесте и смотрим метрики\n",
    "print('Метрики на обучающей выборки ')\n",
    "metrics(my_lg.predict(X_train),y_train)\n",
    "print('Метрики на тестовой выборки ')\n",
    "metrics(my_lg.predict(X_test),y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-5-f7a648a8a967>:20: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Метрики на обучающей выборки \n",
      "Accuracy:  0.5868263473053892\n",
      "Pprecision:  0.5868263473053892\n",
      "Recall:  0.5868263473053892\n",
      "F1:  0.5868263473053892\n",
      "Метрики на тестовой выборки \n",
      "Accuracy:  0.585195530726257\n",
      "Pprecision:  0.585195530726257\n",
      "Recall:  0.585195530726257\n",
      "F1:  0.585195530726257\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "#обучаю модель из sklearn\n",
    "sk_lg=LogisticRegression( max_iter=1000000)\n",
    "sk_lg.fit(X_train,y_train)\n",
    "#делаем предсказания на трейне и на тесте и смотрим метрики\n",
    "print('Метрики на обучающей выборки ')\n",
    "metrics(sk_lg.predict(X_train),y_train)\n",
    "print('Метрики на тестовой выборки ')\n",
    "metrics(sk_lg.predict(X_test),y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Метрики на обучающей выборки \n",
      "Accuracy:  0.6179640718562874\n",
      "Pprecision:  0.6179640718562874\n",
      "Recall:  0.6179640718562874\n",
      "F1:  0.6179640718562874\n",
      "Метрики на тестовой выборки \n",
      "Accuracy:  0.5698324022346368\n",
      "Pprecision:  0.5698324022346368\n",
      "Recall:  0.5698324022346368\n",
      "F1:  0.5698324022346368\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Выводы о моделях по метрикам\n",
    "- Моя модель не переобучилась, т к разница  на метриках между трейном и тестом минимальна.\n",
    "- Моделт из sklearn более склонна к переобучению(разница на трейне и тесте примерно 0.05)\n",
    "- Моя модель показывает себя хуже по метрикам на трейне чем модель из sklearn на трейне, но при этом моя модель показывает себя лучше на тесте чем модель из sklearn на тесте(разница примерно 0.02).\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SVM"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "#Я реализовал SVM в виде класса MYSVM с двумя публичными методами fit- для обучения, predict - для предсказания \n",
    "class MYSVM(object):\n",
    "    # при инициализации класса задается сразу _etha -шаг градиентного спуска,_alpha – коэффициент быстроты\n",
    "    #пропорционального уменьшения весов, _epochs – количество эпох обучения\n",
    "    def __init__(self, etha=0.1, alpha=0.2, epochs=990):\n",
    "        self._epochs = epochs\n",
    "        self._etha = etha\n",
    "        self._alpha = alpha\n",
    "        self._w = None\n",
    "        \n",
    "        \n",
    "    #метод для обучения модели    \n",
    "    def fit(self, X_train, Y_train):\n",
    "        \n",
    "        \n",
    "        for i in range(len(Y_train)):\n",
    "            if Y_train.iloc[i] == 0:\n",
    "                Y_train.iloc[i] = -1\n",
    "        \n",
    "        #добавляем в конец каждого вектора число 1 \n",
    "        X_train = self._add_bias_feature(X_train)\n",
    "        self._w = np.random.normal(loc=0, scale=0.05, size=X_train.shape[1])#задаем первые веса\n",
    "        \n",
    "        \n",
    "        \n",
    "        for epoch in range(self._epochs): \n",
    "            \n",
    "            for i,x in enumerate(X_train):\n",
    "                margin = Y_train.iloc[i]*np.dot(self._w,X_train[i])\n",
    "                if margin >= 1: # классифицируем верно\n",
    "                    self._w = self._w - self._etha*self._alpha*self._w/self._epochs\n",
    "                    \n",
    "                else: # классифицируем неверно или попадаем на полосу разделения при 0<m<1\n",
    "                    self._w = self._w +\\\n",
    "                    self._etha*(Y_train.iloc[i]*X_train[i] - self._alpha*self._w/self._epochs)\n",
    "                    \n",
    "                \n",
    "        for i in range(len(Y_train)):\n",
    "            if Y_train.iloc[i]==-1:\n",
    "                Y_train.iloc[i]=0\n",
    "     \n",
    "    #Приватный метод , добовляющей в конец каждого вектора чисор 1 \n",
    "    def _add_bias_feature(self,a):\n",
    "        \n",
    "        a_extended = np.zeros((a.shape[0],a.shape[1]+1))\n",
    "        a_extended[:,:-1] = a\n",
    "        a_extended[:,-1] = int(1)  \n",
    "        return a_extended\n",
    "    \n",
    "    \n",
    "     #метод для предсказания \n",
    "    def predict(self, X):\n",
    "        y_pred = []\n",
    "        #X_extended = self._add_bias_feature(X)\n",
    "        for i in range(len(X)):\n",
    "            y_pred.append(np.sign(1+np.dot(self._w[1:],X.iloc[i])))\n",
    "        for i in range(len(y_pred)):\n",
    "            if y_pred[i]==-1:\n",
    "                y_pred[i]=0\n",
    "\n",
    "        return y_pred         \n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "my_svm=MYSVM()\n",
    "my_svm.fit(X_train,y_train)\n",
    "print('метрики на обучении')\n",
    "metrics(my_svm.predict(X_train),y_train)\n",
    "print('метрики на тесте')\n",
    "metrics(my_svm.predict(X_test),y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "метрики на обучении\n",
      "Accuracy:  0.5868263473053892\n",
      "Pprecision:  0.5868263473053892\n",
      "Recall:  0.5868263473053892\n",
      "F1:  0.5868263473053892\n",
      "метрики на тесте\n",
      "Accuracy:  0.585195530726257\n",
      "Pprecision:  0.585195530726257\n",
      "Recall:  0.585195530726257\n",
      "F1:  0.585195530726257\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "sk_svm = svm.SVC()\n",
    "sk_svm.fit(X_train, y_train)\n",
    "print('метрики на обучении')\n",
    "metrics(sk_svm.predict(X_train),y_train)\n",
    "print('метрики на тесте')\n",
    "metrics(sk_svm.predict(X_test),y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "метрики на обучении\n",
      "Accuracy:  0.6215568862275449\n",
      "Pprecision:  0.6215568862275449\n",
      "Recall:  0.6215568862275449\n",
      "F1:  0.6215568862275449\n",
      "метрики на тесте\n",
      "Accuracy:  0.5600558659217877\n",
      "Pprecision:  0.5600558659217877\n",
      "Recall:  0.5600558659217877\n",
      "F1:  0.5600558659217877\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Выводы \n",
    "- Моя модель не переобучилась, т к разница  на метриках между трейном и тестом минимальна.\n",
    "- Моделт из sklearn более склонна к переобучению(разница на трейне и тесте примерно 0.06)\n",
    "- Моя модель показывает себя хуже по метрикам на трейне чем модель из sklearn на трейне, но при этом моя модель показывает себя лучше на тесте чем модель из sklearn на тесте(разница примерно 0.02)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Дерево решений"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "#Я реализовать дерево решений в виде класса MyDT с двуми публичными методами , fit - для обучения, predict - для предсказания \n",
    "#остальные методы приватные и используются в публичных\n",
    "class MyDT():\n",
    "    \n",
    "    # объявляем характеристики класса\n",
    "    def __init__(self, max_depth=3, min_size=10):\n",
    "        \n",
    "        self.max_depth = max_depth\n",
    "        self.min_size = min_size\n",
    "        self.value = 0\n",
    "        self.feature_idx = -1\n",
    "        self.feature_threshold = 0\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        \n",
    "    # процедура обучения - сюда передается обучающая выборка\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        \n",
    "        \n",
    "        for i in range(len(y)):\n",
    "            if y.iloc[i] == 0:\n",
    "                y.iloc[i] = -1\n",
    "        \n",
    "        \n",
    "        # начальное значение - среднее значение y\n",
    "        self.value = y.mean()\n",
    "        # начальная ошибка - mse между значением в листе (пока нет\n",
    "        # разбиения, это среднее по всем объектам) и объектами\n",
    "        base_error = ((y - self.value) ** 2).sum()\n",
    "        error = base_error\n",
    "        flag = 0\n",
    "        \n",
    "        # пришли в максимальную глубину\n",
    "        if self.max_depth <= 1:\n",
    "            return\n",
    "    \n",
    "        dim_shape = X.shape[1]\n",
    "        \n",
    "        left_value, right_value = 0, 0\n",
    "        \n",
    "        for feat in range(dim_shape):\n",
    "            \n",
    "            prev_error1, prev_error2 = base_error, 0 \n",
    "            if feat==0:\n",
    "                idxs = np.argsort(X[:, feat])\n",
    "            \n",
    "            # переменные для быстрого переброса суммы\n",
    "            mean1, mean2 = y.mean(), 0\n",
    "            sm1, sm2 = y.sum(), 0\n",
    "            \n",
    "            N = X.shape[0]\n",
    "            N1, N2 = N, 0\n",
    "            thres = 1\n",
    "            \n",
    "            while thres < N - 1:\n",
    "                N1 -= 1\n",
    "                N2 += 1\n",
    "\n",
    "                idx = idxs[thres]\n",
    "                x = X[int(idx), feat]\n",
    "                \n",
    "                # вычисляем дельты - по ним в основном будет делаться переброс\n",
    "                delta1 = (sm1 - y.iloc[idx]) * 1.0 / N1 - mean1\n",
    "                delta2 = (sm2 + y.iloc[idx]) * 1.0 / N2 - mean2\n",
    "                \n",
    "                # увеличиваем суммы\n",
    "                sm1 -= y.iloc[idx]\n",
    "                sm2 += y.iloc[idx]\n",
    "                \n",
    "                # пересчитываем ошибки за O(1)\n",
    "                prev_error1 += (delta1**2) * N1 \n",
    "                prev_error1 -= (y.iloc[idx] - mean1)**2 \n",
    "                prev_error1 -= 2 * delta1 * (sm1 - mean1 * N1)\n",
    "                mean1 = sm1/N1\n",
    "                \n",
    "                prev_error2 += (delta2**2) * N2 \n",
    "                prev_error2 += (y.iloc[idx] - mean2)**2 \n",
    "                prev_error2 -= 2 * delta2 * (sm2 - mean2 * N2)\n",
    "                mean2 = sm2/N2\n",
    "                \n",
    "                # пропускаем близкие друг к другу значения\n",
    "                if thres < N - 1 and np.abs(x - X[idxs[thres + 1], feat]) < 1e-5:\n",
    "                    thres += 1\n",
    "                    continue\n",
    "                \n",
    "                # 2 условия, чтобы осуществить сплит - уменьшение ошибки \n",
    "                # и минимальное кол-о эл-в в каждом листе\n",
    "                if (prev_error1 + prev_error2 < error):\n",
    "                    if (min(N1,N2) > self.min_size):\n",
    "                    \n",
    "                        # переопределяем самый лучший признак и границу по нему\n",
    "                        self.feature_idx, self.feature_threshold = feat, x\n",
    "                        # переопределяем значения в листах\n",
    "                        left_value, right_value = mean1, mean2\n",
    "\n",
    "                        # флаг - значит сделали хороший сплит\n",
    "                        flag = 1\n",
    "                        error = prev_error1 + prev_error2\n",
    "                                     \n",
    "                thres += 1\n",
    " \n",
    "        # ничего не разделили, выходим\n",
    "        if self.feature_idx == -1:\n",
    "            return\n",
    "        \n",
    "        self.left = MyDT(self.max_depth - 1)\n",
    "        # print (\"Левое поддерево с глубиной %d\"%(self.max_depth - 1))\n",
    "        self.left.value = left_value\n",
    "        self.right = MyDT(self.max_depth - 1)\n",
    "        # print (\"Правое поддерево с глубиной %d\"%(self.max_depth - 1))\n",
    "        self.right.value = right_value\n",
    "        \n",
    "        idxs_l = (X[:, self.feature_idx] > self.feature_threshold)\n",
    "        idxs_r = (X[:, self.feature_idx] <= self.feature_threshold)\n",
    "    \n",
    "        self.left.fit(X[idxs_l, :], y[idxs_l])\n",
    "        self.right.fit(X[idxs_r, :], y[idxs_r])\n",
    "        \n",
    "        for i in range(len(y)):\n",
    "            if y.iloc[i]==-1:\n",
    "                y.iloc[i]=0\n",
    "        \n",
    "    def __predict(self, x):\n",
    "        if self.feature_idx == -1:\n",
    "            return self.value\n",
    "        \n",
    "        if x[self.feature_idx] > self.feature_threshold:\n",
    "            return self.left.__predict(x)\n",
    "        else:\n",
    "            return self.right.__predict(x)\n",
    "    \n",
    "    #метод для финального расставления меток \n",
    "    def _prediction(self,x):\n",
    "        if x < 0:\n",
    "            \n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    \n",
    "    #Метод для предсказания \n",
    "    def predict(self, X):\n",
    "        y = np.zeros(X.shape[0])\n",
    "        \n",
    "        for i in range(X.shape[0]):\n",
    "            y[i] = self.__predict(X[i])\n",
    "        \n",
    "        for i in range(len(y)):\n",
    "            y[i]=self._prediction(y[i])\n",
    "        return y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "my_dt=MyDT()\n",
    "my_dt.fit(X_train.values,y_train)\n",
    "print('метрики на обучении')\n",
    "metrics(my_dt.predict(X_train.values),y_train)\n",
    "print('метрики на тесте')\n",
    "metrics(my_dt.predict(X_test.values),y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "метрики на обучении\n",
      "Accuracy:  0.588622754491018\n",
      "Pprecision:  0.588622754491018\n",
      "Recall:  0.588622754491018\n",
      "F1:  0.588622754491018\n",
      "метрики на тесте\n",
      "Accuracy:  0.5782122905027933\n",
      "Pprecision:  0.5782122905027933\n",
      "Recall:  0.5782122905027933\n",
      "F1:  0.5782122905027933\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "dt = DecisionTreeClassifier(max_depth=3, min_samples_leaf=10)\n",
    "dt.fit(X_train,y_train)\n",
    "print('метрики на обучении')\n",
    "metrics(dt.predict(X_train.values),y_train)\n",
    "print('метрики на тесте')\n",
    "metrics(dt.predict(X_test.values),y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "метрики на обучении\n",
      "Accuracy:  0.6389221556886228\n",
      "Pprecision:  0.6389221556886228\n",
      "Recall:  0.6389221556886228\n",
      "F1:  0.6389221556886228\n",
      "метрики на тесте\n",
      "Accuracy:  0.5670391061452514\n",
      "Pprecision:  0.5670391061452514\n",
      "Recall:  0.5670391061452514\n",
      "F1:  0.5670391061452514\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Выводы \n",
    "- Моя модель практичиски не переобучилась, т к разница  на метриках между трейном и тестом минимальна(0.01).\n",
    "- Моделт из sklearn более склонна к переобучению(разница на трейне и тесте примерно 0.09)\n",
    "- Моя модель показывает себя хуже по метрикам на трейне чем модель из sklearn на трейне, но при этом моя модель показывает себя лучше на тесте чем модель из sklearn на тесте(разница примерно 0.02)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
